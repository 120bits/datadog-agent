include: 'https://gitlab-templates.ddbuild.io/slack-notifier/v1/template.yml'

default:
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure
      - unknown_failure
      - api_failure

stages:
  - image_build
  - image_deploy

variables:
  # The SRC_PATH is in the GOPATH of the builders which
  # currently is /go
  SRC_PATH: /go/src/github.com/DataDog/datadog-agent
  # Directory in which we execute the omnibus build.
  # For an unknown reason, it does not go well with
  # a ruby dependency if we build directly into $CI_PROJECT_DIR/.omnibus
  OMNIBUS_BASE_DIR: /.omnibus
  # Directory in which we put the artifacts after the build
  # Must be in $CI_PROJECT_DIR
  OMNIBUS_PACKAGE_DIR: $CI_PROJECT_DIR/.omnibus/pkg/
  # Directory in which we execute the omnibus build for SUSE
  # as we want to separate the RPM built for this distro.
  OMNIBUS_BASE_DIR_SUSE: /.omnibus/suse
  # Directory in which we put the artifacts after the build
  # Must be in $CI_PROJECT_DIR
  OMNIBUS_PACKAGE_DIR_SUSE: $CI_PROJECT_DIR/.omnibus/suse/pkg
  OMNIBUS_BASE_DIR_WIN: c:\omni-base\$CI_RUNNER_ID
  OMNIBUS_BASE_DIR_WIN_OMNIBUS: c:/omni-base/$CI_RUNNER_ID
  DD_AGENT_TESTING_DIR: $CI_PROJECT_DIR/test/kitchen
  STATIC_BINARIES_DIR: bin/static
  DOGSTATSD_BINARIES_DIR: bin/dogstatsd
  AGENT_BINARIES_DIR: bin/agent
  CLUSTER_AGENT_BINARIES_DIR: bin/datadog-cluster-agent
  CLUSTER_AGENT_CLOUDFOUNDRY_BINARIES_DIR: bin/datadog-cluster-agent-cloudfoundry
  SYSTEM_PROBE_BINARIES_DIR: bin/system-probe
  DEB_S3_BUCKET: apt.datad0g.com
  RPM_S3_BUCKET: yum.datad0g.com
  WIN_S3_BUCKET: dd-agent-mstesting
  PROCESS_S3_BUCKET: datad0g-process-agent
  ANDROID_S3_BUCKET: dd-agent-androidtesting
  DEB_RPM_BUCKET_BRANCH: nightly  # branch of the DEB_S3_BUCKET and RPM_S3_BUCKET repos to release to, 'nightly' or 'beta'
  DEB_TESTING_S3_BUCKET: apttesting.datad0g.com
  RPM_TESTING_S3_BUCKET: yumtesting.datad0g.com
  WINDOWS_TESTING_S3_BUCKET_A6: pipelines/A6/$CI_PIPELINE_ID
  WINDOWS_TESTING_S3_BUCKET_A7: pipelines/A7/$CI_PIPELINE_ID
  WINDOWS_BUILDS_S3_BUCKET: $WIN_S3_BUCKET/builds
  ANDROID_BUILDS_S3_BUCKET: $ANDROID_S3_BUCKET/builds
  DEB_RPM_TESTING_BUCKET_BRANCH: testing  # branch of the DEB_TESTING_S3_BUCKET and RPM_TESTING_S3_BUCKET repos to release to, 'testing'
  DD_REPO_BRANCH_NAME: $CI_COMMIT_REF_NAME
  S3_CP_OPTIONS: --only-show-errors --region us-east-1 --sse AES256
  S3_CP_CMD: aws s3 cp $S3_CP_OPTIONS
  S3_ARTIFACTS_URI: s3://dd-ci-artefacts-build-stable/$CI_PROJECT_NAME/$CI_PIPELINE_ID
## comment out both lines below (S3_OMNIBUS_CACHE_BUCKET and USE_S3_CACHING) to allow
## build to succeed with S3 caching disabled.
  S3_OMNIBUS_CACHE_BUCKET: dd-ci-datadog-agent-omnibus-cache-build-stable
  USE_S3_CACHING: --omnibus-s3-cache
  S3_DSD6_URI: s3://dsd6-staging
  RELEASE_VERSION_6: nightly
  RELEASE_VERSION_7: nightly-a7
  DATADOG_AGENT_BUILDIMAGES: v2424505-0439a40
  DATADOG_AGENT_BUILDERS: v2448672-5304c3c
  DATADOG_AGENT_WINBUILDIMAGES: v2468030-cbaf3fe
  DATADOG_AGENT_WINBUILDERS: v2348149-ba6640d
  DATADOG_AGENT_ARMBUILDIMAGES: v2424505-0439a40
  DATADOG_AGENT_SYSPROBE_BUILDIMAGES: v2424505-0439a40
  BCC_VERSION: v0.12.0
  SYSTEM_PROBE_GO_VERSION: 1.13.8

#
# Trigger conditions
#

# run job only when triggered by an external tool (ex: Jenkins). This is used
# for jobs that run both on nightlies and tags
.run_only_when_triggered: &run_only_when_triggered
  only:
    - triggers


# anchor to trigger test kitchen setup, run, and cleanup (so all stages
# are run if one stage is run).  Triggers as defined:
# - master
# - tags (a tagged build)
# - triggers (as above, when triggered by an external tool like jenkins)
# - web (when the build is triggered by a specific build request through the
#        web interface.  This way, if a kitchen run is desired on a specific branch,
#        it can be triggered by requesting a specific build)
#
.run_only_when_testkitchen_triggered: &run_only_when_testkitchen_triggered
  only:
    - master
    - tags
    - triggers
    - web

# run job only when triggered by an external tool (ex: Jenkins) and when
# RELEASE_VERSION_X is NOT "nightly". In this setting we are building either a
# new tagged version of the agent (an RC for example). In both cases the
# artifacts should be uploaded to our staging repository.

.run_only_when_triggered_on_tag_6: &run_only_when_triggered_on_tag_6
  only:
    refs:
      - triggers
  except: # we have to use except since gitlab doens't handle '!=' operator
    variables:
      - $RELEASE_VERSION_6 == "nightly"
      - $RELEASE_VERSION_6 == "" # no  RELEASE_VERSION means a nightly build for omnibus

.run_only_when_triggered_on_tag_7: &run_only_when_triggered_on_tag_7
  only:
    refs:
      - triggers
  except: # we have to use except since gitlab doens't handle '!=' operator
    variables:
      - $RELEASE_VERSION_7 == "nightly-a7"
      - $RELEASE_VERSION_7 == "" # no  RELEASE_VERSION means a nightly build for omnibus

# run job only when triggered by an external tool (ex: Jenkins) and when
# RELEASE_VERSION_X is "nightly". In this setting we build from master and update
# the nightly build for windows, linux and docker.

.run_only_when_triggered_on_nightly: &run_only_when_triggered_on_nightly
  only:
    refs:
      - triggers
    variables:
      - $RELEASE_VERSION_6 == "nightly"
      - $RELEASE_VERSION_7 == "nightly-a7"

# run when not triggered (for jobs we don't want to run on release pipelines)
.skip_when_triggered: &skip_when_triggered
  # TODO (with rules?): exclude triggered pipelines but not nightlies
  except:
    refs:
      - triggers

# Skip job only when RELEASE_VERSION_X is not set
.skip_when_unwanted_on_6: &skip_when_unwanted_on_6
  except:
    variables:
      - $RELEASE_VERSION_6 == ""

.skip_when_unwanted_on_7: &skip_when_unwanted_on_7
  except:
    variables:
      - $RELEASE_VERSION_7 == ""

# Fail if we're running a pipeline on a non-triggered tag build
# NOTE: All jobs with 'needs' dependencies should also 'need' this to workaround a Gitlab issue: https://gitlab.com/gitlab-org/gitlab/issues/31526
fail_on_non_triggered_tag:
  stage: fail_on_tag
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  script:
    - echo CI_PIPELINE_SOURCE=$CI_PIPELINE_SOURCE CI_COMMIT_TAG=$CI_COMMIT_TAG
    - '[[ $CI_COMMIT_TAG == dca-* || $CI_COMMIT_TAG == "" || $CI_PIPELINE_SOURCE != "push" ]]'


# package_build
#
#
#
# image_build
#

.docker_build_job_definition: &docker_build_job_definition
  stage: image_build
  script:
    - aws s3 sync --only-show-errors $S3_ARTIFACTS_URI $BUILD_CONTEXT
    - TAG_SUFFIX=${TAG_SUFFIX:-}
    - BUILD_ARG=${BUILD_ARG:-}
    - TARGET_TAG=$IMAGE:v$CI_PIPELINE_ID-${CI_COMMIT_SHA:0:7}$TAG_SUFFIX-$ARCH
    # Pull base image(s) with content trust enabled
    - pip install -r requirements.txt
    - inv -e docker.pull-base-images --signed-pull $BUILD_CONTEXT/$ARCH/Dockerfile
    # Build testing stage if provided
    - test "$TESTING_ARG" && docker build --file $BUILD_CONTEXT/$ARCH/Dockerfile $TESTING_ARG $BUILD_CONTEXT
    # Build release stage and push to ECR
    - docker build $BUILD_ARG --file $BUILD_CONTEXT/$ARCH/Dockerfile --pull --tag $TARGET_TAG $BUILD_CONTEXT
    - docker push $TARGET_TAG

.docker_build_job_definition_amd64: &docker_build_job_definition_amd64
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/docker:v1907756-26d65dc-18.09.6
  tags: ["runner:docker", "size:large"]
  variables:
    ARCH: amd64

#
# Docker dev image deployments
#


.docker_hub_variables: &docker_hub_variables
  DOCKER_REGISTRY_LOGIN_SSM_KEY: docker_hub_login
  DOCKER_REGISTRY_PWD_SSM_KEY: docker_hub_pwd
  DELEGATION_KEY_SSM_KEY: docker_hub_signing_key
  DELEGATION_PASS_SSM_KEY: docker_hub_signing_pass
  DOCKER_REGISTRY_URL: docker.io
  SRC_AGENT: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
  SRC_DSD: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/dogstatsd
  SRC_DCA: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/cluster-agent

.quay_variables: &quay_variables
  <<: *docker_hub_variables
  DOCKER_REGISTRY_LOGIN_SSM_KEY: quay_login
  DOCKER_REGISTRY_PWD_SSM_KEY: quay_pwd
  DOCKER_REGISTRY_URL: quay.io

.docker_tag_job_definition: &docker_tag_job_definition
  stage: image_deploy
  tags: [ "runner:docker", "size:large" ]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/docker-notary:v1912023-8c8dc1c-0.6.1
  variables:
    <<: *docker_hub_variables
  before_script:
    - export SRC_TAG=v2612354-21a238a
    - DOCKER_REGISTRY_LOGIN=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_LOGIN_SSM_KEY --with-decryption --query "Parameter.Value" --out text)
    - aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_PWD_SSM_KEY --with-decryption --query "Parameter.Value" --out text | docker login --username "$DOCKER_REGISTRY_LOGIN" --password-stdin "$DOCKER_REGISTRY_URL"
    - pip install -r requirements.txt
    - if [[ -z "$DELEGATION_PASS_SSM_KEY" ]]; then echo "No signing key set"; exit 0; fi
    - echo "Importing delegation signing key"
    - export DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DELEGATION_PASS_SSM_KEY --with-decryption --query "Parameter.Value" --out text)
    - export NOTARY_AUTH=$(echo "$DOCKER_REGISTRY_LOGIN:$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_PWD_SSM_KEY --with-decryption --query "Parameter.Value" --out text)" | base64)
    - export NOTARY_DELEGATION_PASSPHRASE="$DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE"
    - aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DELEGATION_KEY_SSM_KEY --with-decryption --query "Parameter.Value" --out text > /tmp/docker.key
    - notary -d ~/.docker/trust key import /tmp/docker.key; rm /tmp/docker.key

dev_master_docker_hub-a6:
  <<: *skip_when_unwanted_on_6
  <<: *docker_tag_job_definition
  needs:
    - fail_on_non_triggered_tag
    - docker_build_agent6
    - docker_build_agent6_jmx
    - docker_build_agent6_py2py3_jmx
  only:
    - master
  script:
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-amd64       datadog/agent-dev:master
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-amd64       datadog/agent-dev:master-py2
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64   datadog/agent-dev:master-jmx
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64   datadog/agent-dev:master-py2-jmx

dev_master_docker_hub-a7:
  <<: *skip_when_unwanted_on_7
  <<: *docker_tag_job_definition
  needs:
    - fail_on_non_triggered_tag
    - docker_build_agent7
    - docker_build_agent7_jmx
  only:
    - master
  script:
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-amd64       datadog/agent-dev:master-py3
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-jmx-amd64   datadog/agent-dev:master-py3-jmx

